{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b958ef8",
   "metadata": {},
   "source": [
    "\n",
    "# HR Analytics â€” Promotion Prediction\n",
    "\n",
    "**Contents**\n",
    "- Problem description\n",
    "- Load data (train/test)\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- Preprocessing and feature engineering\n",
    "- Model training (Random Forest baseline)\n",
    "- Cross-validation and validation metrics\n",
    "- Create submission file\n",
    "\n",
    "This notebook is generated automatically. Run each cell sequentially in a Jupyter environment (or Google Colab).\n",
    "\n",
    "Files used:\n",
    "- `train.csv`\n",
    "- `test.csv`\n",
    "- `sample_submission.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9a0384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "train = pd.read_csv('/mnt/data/train.csv')\n",
    "test = pd.read_csv('/mnt/data/test.csv')\n",
    "sample = pd.read_csv('/mnt/data/sample_submission.csv')\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9969dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Quick EDA\n",
    "display(train.info())\n",
    "display(train.describe(include='all').T)\n",
    "print('\\nMissing values per column:')\n",
    "print(train.isnull().sum())\n",
    "\n",
    "# Target distribution\n",
    "print('\\nTarget value counts:')\n",
    "print(train['is_promoted'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8b1fa3",
   "metadata": {},
   "source": [
    "\n",
    "## Preprocessing plan\n",
    "- Drop `employee_id` (identifier)\n",
    "- Identify categorical and numeric columns\n",
    "- Handle missing values (SimpleImputer)\n",
    "- Encode categorical variables (OneHot or Ordinal where appropriate)\n",
    "- Train a RandomForest baseline model\n",
    "- Use StratifiedKFold cross-validation for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7565ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features\n",
    "X = train.drop(['is_promoted','employee_id'], axis=1)\n",
    "y = train['is_promoted']\n",
    "\n",
    "X_test = test.drop(['employee_id'], axis=1)\n",
    "\n",
    "# Identify columns\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "numeric_candidates = []\n",
    "categorical_candidates = []\n",
    "for c in X.columns:\n",
    "    if X[c].dtype in ['int64','float64']:\n",
    "        if X[c].nunique() <= 10 and c not in ['avg_training_score','age','length_of_service']:\n",
    "            categorical_candidates.append(c)\n",
    "        else:\n",
    "            numeric_candidates.append(c)\n",
    "    else:\n",
    "        categorical_candidates.append(c)\n",
    "\n",
    "numeric_cols = [c for c in numeric_candidates if c in X.columns]\n",
    "categorical_cols = [c for c in categorical_candidates if c in X.columns]\n",
    "\n",
    "print('Numeric columns:', numeric_cols)\n",
    "print('Categorical columns:', categorical_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d8c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(clf, X, y, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "print('CV accuracy scores:', scores)\n",
    "print('CV accuracy mean: {:.4f}'.format(scores.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b091c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Holdout split for quick validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "# Validate\n",
    "y_pred = clf.predict(X_val)\n",
    "print('Validation accuracy:', accuracy_score(y_val, y_pred))\n",
    "print('\\nClassification report:\\n', classification_report(y_val, y_pred))\n",
    "print('\\nConfusion matrix:\\n', confusion_matrix(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train on full training data\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict on test\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "# Prepare submission\n",
    "submission = sample.copy()\n",
    "submission['is_promoted'] = test_preds\n",
    "submission.to_csv('/mnt/data/submission_hr_promotion.csv', index=False)\n",
    "print('Saved submission to /mnt/data/submission_hr_promotion.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save trained model pipeline\n",
    "joblib.dump(clf, '/mnt/data/hr_promotion_pipeline.joblib')\n",
    "print('Saved pipeline to /mnt/data/hr_promotion_pipeline.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa41599",
   "metadata": {},
   "source": [
    "\n",
    "## Next steps (suggestions to improve model)\n",
    "- Feature engineering: create interaction features, bin ages, scale numeric features if needed\n",
    "- Try other models: XGBoost, LightGBM, Logistic Regression (with class weights)\n",
    "- Hyperparameter tuning: GridSearchCV or RandomizedSearchCV\n",
    "- Handle class imbalance if present (SMOTE, class_weight)\n",
    "- Add visual EDA: distribution plots, correlations, boxplots\n",
    "\n",
    "Save this notebook and upload to your GitHub repo along with the data files and the saved pipeline if you want.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
